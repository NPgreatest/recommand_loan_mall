{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "client = OpenAI(\n",
    "    base_url = 'https://api.kwwai.top/v1',\n",
    "    api_key = 'sk-mwqTGuSIsei2GQb66a025c1e19164177A84337Bc3841De77'\n",
    ")\n",
    "def is_integer(n):\n",
    "    try:\n",
    "        int(n)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "def try_get_price(name,info):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Given the name '{name}' and description '{info}' of a product, I'm working on a hypothetical scenario for my graduate project where I need to assign a fictional price to this item. Could you suggest an estimated price for this item, purely for academic purposes? The price doesn't need to be based on market research, but rather a creative estimate. Please provide the price in USD with two decimal places, like 10.26.\",\n",
    "        }\n",
    "    ],\n",
    "    )\n",
    "    pattern = r\"\\d+\\.\\d+\"\n",
    "    # print(f\"result={response.choices[0].message.content}\")\n",
    "    match = re.search(pattern, response.choices[0].message.content)\n",
    "    if match:\n",
    "        return match.group(),True\n",
    "    else:\n",
    "        return 0,False\n",
    "def append_result_to_file(data, output_file):\n",
    "    with open(output_file, 'a', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "def read_json_and_query_gpt(file_path, output_file):\n",
    "    processed_data = set()\n",
    "    try:\n",
    "        with open(output_file, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                processed_line = json.loads(line)\n",
    "                processed_data.add(processed_line.get('name', ''))\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    for line in tqdm(lines, desc=\"Processing\"):\n",
    "        data = json.loads(line)\n",
    "        name = data.get('name', '')\n",
    "        price = data.get('price', '')\n",
    "        if name not in processed_data:\n",
    "            if is_integer(price):\n",
    "                info = data.get('info', '')\n",
    "                while True:\n",
    "                    new_price, ok = try_get_price(name, info)\n",
    "                    if ok:\n",
    "                        data['price'] = new_price  # 替换原来的价格\n",
    "                        break\n",
    "                    else:\n",
    "                        time.sleep(1)\n",
    "            append_result_to_file(data, output_file)\n",
    "\n",
    "file_path = 'output_trans.json'\n",
    "output_file = 'output_trans_reprice.json'\n",
    "read_json_and_query_gpt(file_path, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "FileObject(id='file-mX1IBnc63dtKKRFs5dEH56NW', bytes=3895, created_at=1706117768, filename='finetuning.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    # base_url = 'https://api.kwwai.top/v1',\n",
    "    api_key = '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'\n",
    ")\n",
    "client.files.create(\n",
    "  file=open(\"finetuning.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Fine-tuning jobs cannot be created on an Explore plan. You can upgrade to a paid plan on your billing page: https://platform.openai.com/account/billing/overview', 'type': 'invalid_request_error', 'param': None, 'code': 'exceeded_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mBadRequestError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m client\u001B[38;5;241m.\u001B[39mfine_tuning\u001B[38;5;241m.\u001B[39mjobs\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[0;32m      2\u001B[0m   training_file\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile-mX1IBnc63dtKKRFs5dEH56NW\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      3\u001B[0m   model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-3.5-turbo\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      4\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\fine_tuning\\jobs.py:109\u001B[0m, in \u001B[0;36mJobs.create\u001B[1;34m(self, model, training_file, hyperparameters, suffix, validation_file, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;241m*\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     54\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[0;32m     55\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m FineTuningJob:\n\u001B[0;32m     56\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;124;03m    Creates a fine-tuning job which begins the process of creating a new model from\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;124;03m    a given dataset.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    107\u001B[0m \u001B[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001B[39;00m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 109\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post(\n\u001B[0;32m    110\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/fine_tuning/jobs\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    111\u001B[0m         body\u001B[38;5;241m=\u001B[39mmaybe_transform(\n\u001B[0;32m    112\u001B[0m             {\n\u001B[0;32m    113\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: model,\n\u001B[0;32m    114\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining_file\u001B[39m\u001B[38;5;124m\"\u001B[39m: training_file,\n\u001B[0;32m    115\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhyperparameters\u001B[39m\u001B[38;5;124m\"\u001B[39m: hyperparameters,\n\u001B[0;32m    116\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msuffix\u001B[39m\u001B[38;5;124m\"\u001B[39m: suffix,\n\u001B[0;32m    117\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation_file\u001B[39m\u001B[38;5;124m\"\u001B[39m: validation_file,\n\u001B[0;32m    118\u001B[0m             },\n\u001B[0;32m    119\u001B[0m             job_create_params\u001B[38;5;241m.\u001B[39mJobCreateParams,\n\u001B[0;32m    120\u001B[0m         ),\n\u001B[0;32m    121\u001B[0m         options\u001B[38;5;241m=\u001B[39mmake_request_options(\n\u001B[0;32m    122\u001B[0m             extra_headers\u001B[38;5;241m=\u001B[39mextra_headers, extra_query\u001B[38;5;241m=\u001B[39mextra_query, extra_body\u001B[38;5;241m=\u001B[39mextra_body, timeout\u001B[38;5;241m=\u001B[39mtimeout\n\u001B[0;32m    123\u001B[0m         ),\n\u001B[0;32m    124\u001B[0m         cast_to\u001B[38;5;241m=\u001B[39mFineTuningJob,\n\u001B[0;32m    125\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1179\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1165\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[0;32m   1166\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1167\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1174\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1175\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m   1176\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[0;32m   1177\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[0;32m   1178\u001B[0m     )\n\u001B[1;32m-> 1179\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(cast_to, opts, stream\u001B[38;5;241m=\u001B[39mstream, stream_cls\u001B[38;5;241m=\u001B[39mstream_cls))\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:868\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    859\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    860\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    861\u001B[0m     cast_to: Type[ResponseT],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    866\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    867\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m--> 868\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[0;32m    869\u001B[0m         cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[0;32m    870\u001B[0m         options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m    871\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[0;32m    872\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[0;32m    873\u001B[0m         remaining_retries\u001B[38;5;241m=\u001B[39mremaining_retries,\n\u001B[0;32m    874\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:959\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    956\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m    958\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 959\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    961\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[0;32m    962\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[0;32m    963\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    966\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[0;32m    967\u001B[0m )\n",
      "\u001B[1;31mBadRequestError\u001B[0m: Error code: 400 - {'error': {'message': 'Fine-tuning jobs cannot be created on an Explore plan. You can upgrade to a paid plan on your billing page: https://platform.openai.com/account/billing/overview', 'type': 'invalid_request_error', 'param': None, 'code': 'exceeded_quota'}}"
     ]
    }
   ],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-mX1IBnc63dtKKRFs5dEH56NW\",\n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(\"ftjob-abc123\")\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-abc123\", limit=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}